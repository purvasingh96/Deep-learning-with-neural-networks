{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Back_propogation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPdfvEPAD46QR/rOEn3FxN3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/purvasingh96/Deep-learning-with-neural-networks/blob/master/Notes/Ch_5_Deep_Forward_Networks/Ch_5.1_Back_Propagation/Back_propogation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyShBNUVEbbT",
        "colab_type": "text"
      },
      "source": [
        "# Backpropogation \n",
        "Consider the example below -\n",
        "Suppose there are two input values, one hidden unit, and one output unit, with sigmoid activations on the hidden and output units. The following image depicts this network. <br>\n",
        "<img src=\"https://github.com/purvasingh96/Deep-learning-with-neural-networks/blob/master/Notes/Ch_5_Deep_Forward_Networks/Ch_5.1_Back_Propagation/images/back_prop_example.png?raw=1\"></img> \n",
        "\n",
        "# Backpropogation Algorithm\n",
        "\n",
        "## Step 1: Calculate input to hidden layer\n",
        "Assuming out target is *y=1*, calculate forward pass - \n",
        "\n",
        "<img src=\"https://github.com/purvasingh96/Deep-learning-with-neural-networks/blob/master/Notes/Ch_5_Deep_Forward_Networks/Ch_5.1_Back_Propagation/images/forward_pass.png?raw=1\"></img>\n",
        "\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S588W41bGZwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkB-9QoSGeTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "x = np.array([0.5, 0.1, -0.2])\n",
        "target = 0.6\n",
        "learnrate = 0.5\n",
        "\n",
        "weights_input_to_hidden = np.array([[0.5, -0.6],\n",
        "                                 [0.1, -0.2],\n",
        "                                 [0.1, 0.7]])\n",
        "\n",
        "weights_hidden_to_output = np.array([0.1, -0.3])\n",
        "\n",
        "# calculating forward pass\n",
        "hidden_layer_input = np.dot(x, weights_input_to_hidden)\n",
        "hidden_layer_output = sigmoid(hidden_layer_input)\n",
        "\n",
        "output_layer_in = np.dot(hidden_layer_output, weights_hidden_to_output)\n",
        "output = sigmoid(output_layer_in)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X614BwMJGy-",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: Perform backward-pass\n",
        "<img src=\"https://github.com/purvasingh96/Deep-learning-with-neural-networks/blob/master/Notes/Ch_5_Deep_Forward_Networks/Ch_5.1_Back_Propagation/images/back_prop_2.png?raw=1\"></img>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd-hUAVHG0Z9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "error = target-output\n",
        "output_error_term = error * output * (1-output)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aqiy0h4iPInU",
        "colab_type": "text"
      },
      "source": [
        "## Step 3: Find output and hidden error term\n",
        "<img src=\"https://github.com/purvasingh96/Deep-learning-with-neural-networks/blob/master/Notes/Ch_5_Deep_Forward_Networks/Ch_5.1_Back_Propagation/images/back_prop_3.png?raw=1\"></img> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqjK4l1rPBNe",
        "colab_type": "code",
        "outputId": "0b7248f8-ca01-489a-f4ab-ec3b5775694a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "hidden_error_term = np.dot(output_error_term, weights_hidden_to_output) * hidden_layer_output * (1-hidden_layer_output)\n",
        "\n",
        "\n",
        "# x = np.array([0.5, 0.1, -0.2])\n",
        "# x[:, None] = [[ 0.5]\n",
        "#               [ 0.1]\n",
        "#               [-0.2]]\n",
        "\n",
        "\n",
        "delta_w_h_o = learnrate * output_error_term * hidden_layer_output\n",
        "delta_w_i_h = learnrate * hidden_error_term * x[:, None]\n",
        "\n",
        "print('Change in weights for hidden layer to output layer:')\n",
        "print(delta_w_h_o)\n",
        "print('Change in weights for input layer to hidden layer:')\n",
        "print(delta_w_i_h)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Change in weights for hidden layer to output layer:\n",
            "[0.00804047 0.00555918]\n",
            "Change in weights for input layer to hidden layer:\n",
            "[[ 1.77005547e-04 -5.11178506e-04]\n",
            " [ 3.54011093e-05 -1.02235701e-04]\n",
            " [-7.08022187e-05  2.04471402e-04]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZakaByZNUr32",
        "colab_type": "text"
      },
      "source": [
        "## Update weights\n",
        "<img src=\"https://github.com/purvasingh96/Deep-learning-with-neural-networks/blob/master/Notes/Ch_5_Deep_Forward_Networks/Ch_5.1_Back_Propagation/images/back_prop_final_algo.png?raw=1\"></img>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZZ926btU68Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import numpy as np\n",
        "from data_prep import features, targets, features_test, targets_test\n",
        "\n",
        "np.random.seed(21)\n",
        "\n",
        "def sigmoid(x):\n",
        "    \"\"\"\n",
        "    Calculate sigmoid\n",
        "    \"\"\"\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "n_hidden = 2  # number of hidden units\n",
        "epochs = 900\n",
        "learnrate = 0.005\n",
        "\n",
        "n_records, n_features = features.shape\n",
        "last_loss = None\n",
        "# Initialize weights\n",
        "weights_input_hidden = np.random.normal(scale=1 / n_features ** .5,\n",
        "                                        size=(n_features, n_hidden))\n",
        "weights_hidden_output = np.random.normal(scale=1 / n_features ** .5,\n",
        "                                         size=n_hidden)\n",
        "\n",
        "for e in range(epochs):\n",
        "    del_w_input_hidden = np.zeros(weights_input_hidden.shape)\n",
        "    del_w_hidden_output = np.zeros(weights_hidden_output.shape)\n",
        "    for x, y in zip(features.values, targets):\n",
        "        ## Forward pass ##\n",
        "        # TODO: Calculate the output\n",
        "        hidden_input = np.dot(x, weights_input_hidden)\n",
        "        hidden_output = sigmoid(hidden_input)\n",
        "        output = sigmoid(np.dot(hidden_output, weights_hidden_output))\n",
        "\n",
        "        ## Backward pass ##\n",
        "        # TODO: Calculate the network's prediction error\n",
        "        error = y-output\n",
        "\n",
        "        # TODO: Calculate error term for the output unit\n",
        "        output_error_term = error * output * (1-output)\n",
        "\n",
        "        ## propagate errors to hidden layer\n",
        "\n",
        "        # TODO: Calculate the hidden layer's contribution to the error\n",
        "        hidden_error = np.dot(output_error_term, weights_hidden_output)\n",
        "        \n",
        "        # TODO: Calculate the error term for the hidden layer\n",
        "        hidden_error_term = hidden_error * hidden_output * (1-hidden_output)\n",
        "        \n",
        "        # TODO: Update the change in weights\n",
        "        del_w_hidden_output += output_error_term * hidden_output\n",
        "        del_w_input_hidden += hidden_error_term * x[:, None]\n",
        "\n",
        "    # TODO: Update weights  (don't forget to division by n_records or number of samples)\n",
        "    weights_input_hidden += learnrate * del_w_input_hidden/n_records\n",
        "    weights_hidden_output += learnrate * del_w_hidden_output/n_records\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}